---
title: "Genre, not content, drives *shall* usage in legal texts"
author: "Tilly Brooks (teb44@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

In their 2024 article "Even laypeople use legalese," Martínez et al. (2024) run two experiments to better understand why legal language ("legalese") is so complex, as measured through the use of center-embedding.  Martínez et al. test two hypotheses about the complexity of legal language, the magic spell hypothesis and the copy-and-edit hypothesis.  The magic spell hypothesis posits that legalese is purposefully written in a complex manner to give it a “ritualistic, spell-like element” as a performative utterance.  The copy-and-edit hypothesis proposes that legalese is complex because it is the product of an iterative writing process in which additional information is inserted into existing sentences rather than added in separate ones.  Across two production experiments, participants without legal training were tasked with writing stories, laws, and unoffical descriptions about crimes from scratch and in a step-by-step writing and editing process.  The authors find that laypeople use more center-embedded syntax when writing legal texts, but that content produced through a writing and editing process does not not contain more center-embedded syntax than content produced all at once.  These findings are consistent with the authors' magic spell hypothesis but do not support the copy-and-edit hypothesis.  At a theoretical level, these findings offer support for the view that the linguistic complexity associated with legal language functions as an indicator of the law's performative effects.

In this replication project, I implement an experiment which prompts participants to write visitors' guides and laws describing certain crimes.  I aim to replicate the finding that it is genre, not writing process which motivates drafters of legal language to use complex language. In addition, I aim to assess whether usage of a linguistic property other than center-embedding (*i.e.*, the central modal *shall*) varies by genre. 



## Methods

The experiment uses a within-subject design in which participants are instructed to (1) pretend they are tour guides and write a summary of a specific criminal statute for visiting tourists; and (2) pretend they are lawmakers and write a draft law about a specific crime.  As an additional manipulation, participants are instructed to write from scratch (the "from scratch condition") in some of their trials and in an editing process (the "editing condition") in the other trials  In both processes, participants are instructed to write a law or guidebook description based on provided specifications describing crimes.  After completing their law or guidebook, participants move on to the next page.  In the from scratch condition, participants move on to the next trial.  In the editing condition, participants are informed that their supervisor (if in the tour guide condition) or their fellow lawmakers (if in the legal condition) has requested that they revise their original draft and are given additional specifications to incorporate into their draft. Participants then revise their original entry to reflect the added specifications.

### Power Analysis
Martínez et al. (2024) report an odds ratio of 8.3 for their experiment.  Given this, a sample of approximately 52 would be needed to achieve 80% power, a sample of approximately 68 would be needed to achieve 90% power, and a sample of approximately 84 would be needed to achieve 95% power.


```{r}
library(pwr)
your_d = log(8.3)*((sqrt(3))/pi)
# For t-tests
pwr.t.test(d = your_d, sig.level = 0.05, power = 0.80, type = "two.sample", 
           alternative = "two.sided")
```
```{r}

your_d = log(8.3)*((sqrt(3))/pi)
# For t-tests
pwr.t.test(d = your_d, sig.level = 0.05, power = 0.90, type = "two.sample", 
           alternative = "two.sided")
```
```{r}

your_d = log(8.3)*((sqrt(3))/pi)
# For t-tests
pwr.t.test(d = your_d, sig.level = 0.05, power = 0.95, type = "two.sample", 
           alternative = "two.sided")
```


### Planned Sample

In order to achieve 80% power and account for the possibility of participants dropping out, the planned sample size for this project is 60.  Participants who are native speakers of U.S. English will be recruited on the platform Prolific.

### Materials
The quoted portions of this section are drawn directly from Martínez et al. (2024).  
The materials in the experiment consisted of eight items.  Each item consisted of instructions to write a law or guide for tourists describing the details of a specific crime.  For each item, two manipulations were available, genre and sequencing.  The genre manipulation consisted of a legal condition and a tour guide condition.  In the legal condition, participants were asked to write a law matching the provided specifications of a crime.  In the tour guide condition, participants were asked to prepare a visitors' guide describing the contents of the provided specifications of a crime.  "Both conditions had an associated cover story explaining the motivation behind the task. In the legal condition, participants were told that they were a 'lawmaker' who was 'tasked with writing a law that prohibits a certain crime, and specifies the punishment for that crime if the crime is committed.'"  In the tour guide condition, participants were told that they were a "tour guide working in a country with strict crime laws" who was "tasked with writing a description of the precondition for a particular crime in your country, as well as the punishment for committing that crime." 

"The second manipulation was sequencing, whose conditions consisted of a from-scratch condition and an editing condition. In the from-scratch condition, the details and propositions of the crime were presented all at once. In the editing condition, in contrast, the propositions were presented in two stages. In stage 1 (Fig.3), the version of the crime included within the instructions was paired-down and did not contain all of the propositions. In Stage 2, the version of the crime included all of the propositions, and the instructions directed participants to edit their text so as to include all of the additional instructions (see blue text of Fig. 3)."

### Procedure	
The quoted portions of this section are drawn directly from Martínez et al. (2024).  
"Participants were recruited via the online platform Prolific." I conducted a power analysis based on the findings in Martínez et al. (2024) to compute sample size.  Based on this analysis, I determined that a minimum of 52 participants would be necessary to achieve at least 80% power.  In order to accommodate this and account for potential exclusions, I recruited 60 participants.

"Participants were eligible if they resided in the United States, were 18 years or older, and native speakers of English. Each participant completed 8 trials of the same series of tasks"

"On a given trial, participants would be presented with materials in one of the four conditions and asked to write either a law or story in accordance with the material’s instructions. As noted above, when in the from-scratch condition, participants were asked to draft their text all at once, whereas in the editing condition, participants were first asked to write an initial draft based on a paired-down version of the crime described, and then subsequently presented with the full version of the crime and asked to edit their draft to incorporate the additional details associated with that version." No participant saw the same item more than once and was presented with each of the four conditions at least once.  Each participant saw One item in the tour guide, editing condition, three items in the tour guide, from scratch condition, two items in the law, editing condition, and two items in the law, from scratch condition.

Before each trial, participants were informed of the genre of the upcoming trial and prompted to confirm that they they understood their role for the trial. "Participants were not allowed to proceed to the trial until answering the comprehension check correctly."

"Prior to completing the first trial, participants were asked to promise that they would not use a language model [such as generative pre-trained transformer (GPT)] to complete the task."

"Participants were retained in the analysis if they completed all trials and were determined not to use a language model in their responses."  Thus 67 out of 70 participants were retained in the final analysis.

### Analysis Plan
Participant responses will be extracted and then analyzed for how *shall* is used.  I will use quantitative analysis to assess the frequency of *shall* usage by trial and genre.  The effect of trial and genre manipulation on *shall* usage will be assessed using two models: a random effects poisson regression with frequency of *shall* usage in participant responses as the outcome variable and a random effects logistic regression using the presence or absence of *shall* as the outcome variable.  Genre is the fixed effect of interest and random effects consist of participant and item. Because the primary analysis of interest in this replication is distinct from that in the original paper, this analysis will also be applied Martínez et al.'s (2024) results.  In the case of trials in the editing condition, only the final response is considered.

I assess the authors' magic spell and copy-and-edit hypotheses.  If the magic spell hypothesis is correct, I expect to find that there is a significant effect of genre on *shall* usage, with *shall* being used more frequently in the legal condition than the tour guide condition.  If the copy-and-edit hypothesis is correct, I expect to find a significant effect of sequencing on *shall* usage, but relative similarity in *shall* usage in legal and tour guide trials.  In addition to assessing these two hypotheses, I introduce and another hypothesis: the *deonticity expressing hypothesis*.  According to this hypothesis, legal language uses *shall* at higher rates than other genres because its function is to describe deontic objects like duties and prohibitions.  If this hypothesis is correct, I expect that there will not be a significant difference in *shall* usage across the two genres or sequencing conditions.  Rather, they deonticity expressing hypothesis predicts that usage of *shall* will be relatively high and constant across the four conditions in the experiment because participants will be describing deontic objects in each trial.


### Differences from Original Study

There were a number of differences between this project and the original study.

**Sample Size**: The sample size for the replication project (60 participants recruited for the main sample) is substantially smaller than that in Martínez et al. 2024 (220 participants recruited).  Based on the power analysis conducted for this project, this smaller sample is sufficient for 80% power.

**Materials **:  The crime specifications used in this experiment are the same as those used in Martínez et al.'s experiment 1, but the manipulations were different.  First, the genre manipulation involves a legal condition and a tour guide condition rather than a legal condition and a story condition.  This is the genre manipulation used in Martínez et al.'s second experiment.  Like experiment 1, the sequencing condition is retained, but participants are exposed to one item in the tour guide & editing condition, three items in the tour guide & from scratch condition, two items in the legal & editing condition, and two items in the legal & from scratch condition.  Where the analysis of the replication focuses on genre rather than sequencing, this difference is not anticipated to make a substantial difference in the findings of this project.

**Procedure **: I did not ask participants to confirm that they did not use a language model at the end of the final trial.  Martínez et al. excluded participants who did not complete all trials or who were determined to have used a language model in their responses. In addition, the comprehension check between trials in my experiment prompted participants to click a button indicating that they understood their role rather than asking them to type their role into a text box.

**Analysis **:  There are two major analytic differences between the original study and this replication project.  First, usage of the modal *shall* is the main focus of analysis rather than center-embedding.  Second, genre is the primary manipulation of interest rather than genre and sequencing (although I still assess the effect of sequencing on *shall* usage). 


#### Actual Sample
  The final sample includes 67 participants.  Three participants were excluded for not completing all trials.

#### Differences from pre-data collection methods plan
I had to run the main sample twice due to an issue with OSF.  Other than this, there were no differences from the pre-data collection methods plan.

## Results


### Data preparation

#### Data organization

```{r include=F}
# import needed packages
library(tidyverse)
library(ggthemes)
library(jsonlite)
library(purrr)
library(ggplot2)
library(lme4)
library(patchwork)
# use a nicer theme
theme_set(theme_few())


# defining the file path to data from my main sample
data_path <- "/Users/tillybrooks/Library/CloudStorage/OneDrive-Stanford/linguistics/spring 2025/psycholinguistics/project_analysis/main_sample"

# defining file path to data from the original experiment
exp1_path <- "/Users/tillybrooks/Library/CloudStorage/OneDrive-Stanford/linguistics/spring 2025/psycholinguistics/project_analysis/original_study_data1"
exp2_path <- "/Users/tillybrooks/Library/CloudStorage/OneDrive-Stanford/linguistics/spring 2025/psycholinguistics/project_analysis/original_study_data2"

#combining CSVs from my main sample into a single data frame
all_data <- list.files(data_path, pattern = "*.csv", full.names = TRUE) %>%
  map_dfr(read_csv, .id="file", show_col_types = FALSE)

# combining responses from from Martínez et al. experiment 1 into a single data frame
# NOTE: these responses include only the final version of the editing condition responses and the guilt second responses

cols_of_interest = c("1_law_seq_R", "2_law_full_R", "3_story_seq_R", "4_story_full_R",
  "5_law_seq_R", "6_law_full_R", "7_story_seq_R", "8_story_full_R",
  "1_law_full_R", "2_story_seq_R", "3_story_full_R", "4_law_seq_R",
  "5_law_full_R", "6_story_seq_R", "7_story_full_R", "8_law_seq_R",
  "1_story_seq_R", "2_story_full_R", "3_law_seq_R", "4_law_full_R",
  "5_story_seq_R", "6_story_full_R", "7_law_seq_R", "8_law_full_R", "PROLIFIC_PID")

exp1_data <- list.files(exp1_path, pattern = "*.csv", full.names = TRUE) %>%
  map_dfr(~ read_csv(.x, show_col_types = FALSE) %>%
            select(all_of(cols_of_interest)))

# remove first three columns of exp1_data (not responses)
exp1_data <- exp1_data %>% 
  slice(-1:-3)

# repeat process for experiment 2 data
relevant_cols = c("item", "genre","response",  "PROLIFIC_PID")

exp2_data <- read_csv( "/Users/tillybrooks/Library/CloudStorage/OneDrive-Stanford/linguistics/spring 2025/psycholinguistics/project_analysis/original_study_data2/responses_with_mistakes_preregistered_experiment_2.csv", show_col_types = FALSE) %>%
  select(all_of(relevant_cols))

#extract the data
extract_response <- function(x) {
  if (is.na(x) || !grepl("\\{\\s*\"response\"\\s*:", x)) return(NA_character_)
  tryCatch(fromJSON(x)$response, error = function(e) NA_character_)
}

all_data <- all_data %>%
  mutate(response = map_chr(response, extract_response))

#filter trial number so only second part of editing condition shows

all_data <- all_data %>%
  filter(!(trial_index %in% c(5,10, 15)))

#filter data to exclude test files and participants who did not complete all trials
all_data <- all_data %>%
  filter(!(file %in% c(1, 8,18,38,58, 59,62,65)))

# filter data to show only responses
all_data <- all_data %>%
  filter(trial_type == "survey-html-form")

#reshape experiment 1 data from Martínez et al. (2024)
exp1_data <- exp1_data %>%
  pivot_longer(
    cols = ends_with("_R"),  # adjust if necessary
    names_to = "column_name",
    values_to = "response"
  )

#filter N/A responses from exp1_data
exp1_data <- exp1_data %>%
  filter(!is.na(response))
```

#### Column Creation

```{r}

# add column for genre to main data
all_data <- all_data %>%
  mutate(
    domain = case_when(
      condition %in% c("law, editing", "law, from scratch") ~ "legal",
      condition %in% c("tour guide, editing", "tour guide, from scratch") ~ "tourguide",
      TRUE ~ NA_character_
    )
  )



# add column for sequencing
all_data <- all_data %>%
  mutate(
    sequencing = case_when(
      condition %in% c("tour guide, from scratch", "law, from scratch") ~ "from scratch",
      condition %in% c("tour guide, editing", "law, editing") ~ "editing",
      TRUE ~ NA_character_
    )
  )

# add columns for genre and sequencing to experiment 1 data
# NOTE: it is not necessary to go trhouhg this process for the experiment 2 data because there is no sequencing manipulation and the data already includes a genre column
exp1_data <- exp1_data %>%
  mutate(
    domain = if_else(str_detect(column_name, "law"), "legal", "fiction_author"),
    sequencing = if_else(str_detect(column_name, "full"), "from_scratch", "editing")
  )


#get total number of shalls used in main data
shall_count <- all_data %>%
  filter(!is.na(response)) %>%
  mutate(num_shall = str_count(response, regex("\\bshall\\b", ignore_case = TRUE))) %>%
  summarise(total = sum(num_shall))

#get total number of shalls used in experiment 1 responses
exp1_shall_count <- exp1_data %>%
  mutate(num_shall_exp1 = str_count(response, regex("\\bshall\\b", ignore_case = TRUE))) %>%
  summarise(total = sum(num_shall_exp1))

#get total number of shalls used in experiment 2 responses
exp2_shall_count <- exp2_data %>%
  mutate(num_shall_exp2 = str_count(response, regex("\\bshall\\b", ignore_case = TRUE))) %>%
  summarise(total = sum(num_shall_exp2))


# add column counting shalls per row to main data frame
all_data <- all_data %>%
  mutate(num_shall = str_count(response, regex("\\bshall\\b", ignore_case = TRUE)))

# create a column documenting shall usage as a binary outcome variable
all_data <- all_data %>%
  mutate(shall_used = ifelse(num_shall > 0, 1, 0))

# add column counting shalls per row to experiment 1 data frame
exp1_data <- exp1_data %>%
  mutate(num_shall_exp1 = str_count(response, regex("\\bshall\\b", ignore_case = TRUE)))

# create a column documenting shall usage as a binary outcome variable
exp1_data <- exp1_data %>%
  mutate(shall_used = ifelse(num_shall_exp1 > 0, 1, 0))

# add column counting shalls per row to experiment 2 data frame
exp2_data <- exp2_data %>%
  mutate(num_shall_exp2 = str_count(response, regex("\\bshall\\b", ignore_case = TRUE)))

# create a column documenting shall usage as a binary outcome variable
exp2_data <- exp2_data %>%
  mutate(shall_used = ifelse(num_shall_exp2 > 0, 1, 0))
```

### Confirmatory analysis
```{r}
#get shall count by domain for main sample
shall_by_domain <- all_data %>%
  group_by(domain) %>%
  summarise(total_shall = sum(num_shall, na.rm = TRUE),
            mean_shall = mean(num_shall, na.rm = TRUE),
            n = n())
#shall_by_domain

#get shall count by domain for experiment 1
exp1_shall_by_domain <- exp1_data %>%
  group_by(domain) %>%
  summarise(total_shall_exp1 = sum(num_shall_exp1, na.rm = TRUE),
            mean_shall_exp1 = mean(num_shall_exp1, na.rm = TRUE),
            n = n())
exp1_shall_by_domain

#get shall count by domain for experiment 2
exp2_shall_by_domain <- exp2_data %>%
  group_by(genre) %>%
  summarise(total_shall_exp2 = sum(num_shall_exp2, na.rm = TRUE),
            mean_shall_exp2 = mean(num_shall_exp2, na.rm = TRUE),
            n = n())
#exp2_shall_by_domain 

#get shall count by sequencing for main sample
shall_by_sequencing <- all_data %>%
  group_by(sequencing) %>% 
  summarise(total_shall = sum(num_shall, na.rm = TRUE),
            mean_shall = mean(num_shall, na.rm = TRUE),
            n = n())

#shall_by_sequencing

#get shall count by sequencing for experiment 1
exp1_shall_by_sequencing <- exp1_data %>%
  group_by(sequencing) %>%
  summarise(total_shall_exp1 = sum(num_shall_exp1, na.rm = TRUE),
            mean_shall_exp1 = sum(num_shall_exp1, na.rm = TRUE),
            n = n())

#exp1_shall_by_sequencing
```
#### Visualizations of results from Martínez et al. (2024)
Although the key analysis of interest in this project is distinct from that used in Martínez et al. (2024), the data from the authors' experiment can be analyzed according to the method used here.  The visualizations below offer support for the view that genre is more impactful on *shall* usage than writing condition.  The data from experiments 1 and 2 in Martínez et al. (2024) reveal that there is an observable difference in mean *shall* usage between legal and non-legal writing, even when the conceptual complexity is consistent across tasks.  In addition, data from experiment 1 indicates that the difference in *shall* usage by writing condition is not as large as that observed across genres.  To the extent that *shall* usage is able to be used as a proxy measure for center-embedding usage, this is consistent with the authors' findings in the original study.  

```{r, figures-side-exp1, fig.show="hold", out.width="100%"}
# barplot showing shall usage by genre for experiment 1
exp1figa <- exp1_data %>%
  filter(!is.na(domain))%>%
  mutate(domain = factor(domain, levels = c("legal", "fiction_author"))) %>%
  group_by(domain)%>%
  summarise(
    mean_shall_exp1 = mean(num_shall_exp1, na.rm = TRUE),
    se_exp1 = sd(num_shall_exp1, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = domain, y = mean_shall_exp1)) +
  geom_bar(stat = "identity", fill = "chocolate4") +
  geom_errorbar(aes(ymin = mean_shall_exp1 - se_exp1, ymax = mean_shall_exp1 + se_exp1), width = 0.2) +
  labs(
    title = "Use of 'shall' by genre (exp.1)",
     x = "Genre",
    y = "Mean number of 'shall' tokens by response") +
  theme_minimal()
  

exp1figb <- exp1_data %>%
  filter(!is.na(sequencing))%>%
  group_by(sequencing)%>%
  summarise(
    mean_shall_exp1 = mean(num_shall_exp1, na.rm = TRUE),
    se_exp1 = sd(num_shall_exp1, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = sequencing, y = mean_shall_exp1)) +
  geom_bar(stat = "identity", fill = "purple") +
  geom_errorbar(aes(ymin = mean_shall_exp1 - se_exp1, ymax = mean_shall_exp1 + se_exp1), width = 0.2) +
  labs(
    title = "Use of 'shall' by sequencing (exp.1)",
     x = "Writing Condition",
    y = "Mean number of 'shall' tokens by response") +
  theme_minimal()

exp1figa + exp1figb
```

```{r}
# barplot showing shall usage by genre for experiment 2
exp2fig <- exp2_data %>%
  filter(!is.na(genre))%>%
  group_by(genre)%>%
  summarise(
    mean_shall_exp2 = mean(num_shall_exp2, na.rm = TRUE),
    se_exp2 = sd(num_shall_exp2, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = genre, y = mean_shall_exp2)) +
  geom_bar(stat = "identity", fill = "purple") +
  geom_errorbar(aes(ymin = mean_shall_exp2 - se_exp2, ymax = mean_shall_exp2 + se_exp2), width = 0.2) +
  labs(
    title = "Average use of 'shall' by genre in experiment 2",
     x = "Genre",
    y = "Mean number of 'shall' tokens by response") +
  theme_minimal()

exp2fig
```

 
#### Visualizations from main sample
Consistent with the findings in Martínez et al. (2024), data from the replication experiment indicate that genre has a greater effect on *shall* usage than writing condition.  This is consistent with the analysis above.
```{r, figures-side, fig.show="hold", out.width="100%"}
#barplot showing shall usage by genre for main sample
figa <- all_data %>%
  filter(!is.na(domain))%>%
  group_by(domain) %>%
  summarise(
    mean_shall = mean(num_shall, na.rm = TRUE),
    se = sd(num_shall, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = domain, y = mean_shall)) +
  geom_bar(stat = "identity", fill = "chocolate4") + 
  geom_errorbar(aes(ymin = mean_shall -se, ymax = mean_shall + se), width = 0.2) +
  labs(
    title = "Use of 'shall' by genre in main sample",
    x = "Genre",
    y = "Mean number of 'shall' tokens by response"
  ) +
  theme_minimal()

# shall usage by sequencing
# barplot to show shall usage by sequencing
figb <- all_data %>%
  filter(!is.na(sequencing))%>%
  group_by(sequencing) %>%
  summarise(
    mean_shall = mean(num_shall, na.rm = TRUE),
    se = sd(num_shall, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = sequencing, y = mean_shall)) +
  geom_bar(stat = "identity", fill = "purple") + 
  geom_errorbar(aes(ymin = mean_shall -se, ymax = mean_shall + se), width = 0.2) +
  labs(
    title = "Use of 'shall' by sequencing",
    x = "Writing Condition",
    y = "Mean number of 'shall' tokens by response"
  ) +
  theme_minimal()

figa + figb
```
Looking at all four conditions together, average *shall* usage is higher in trials in the legal genre regardless of whether the text was written from scratch or in an iterative process.
```{r}
#make a barplot to show shall usage by condition
all_data %>%
  filter(!is.na(condition))%>%
  group_by(condition) %>%
  summarise(
    mean_shall = mean(num_shall, na.rm = TRUE),
    se = sd(num_shall, na.rm = TRUE) / sqrt(n())
  ) %>%
  ggplot(aes(x = condition, y = mean_shall)) +
  geom_bar(stat = "identity", fill = "plum") + 
  geom_errorbar(aes(ymin = mean_shall -se, ymax = mean_shall + se), width = 0.2) +
  labs(
    title = "Average use of 'shall' by condition",
    x = "Condition",
    y = "Mean number of 'shall' tokens by response"
  ) +
  theme_minimal()
```
Overall, these results are like to Martínez et al.'s findings, which indicated that genre effects center-embedding usagh more than writing process.  Similarly, genre appears to have a much greater effect on *shall* usage than sequencing.
![Martínez et al. experiment 1 results](martinez et al. visual.png)
Although there is variation in *shall* usage across trials, writing in the legal genre uses *shall* at much higher rates than writing in the tour guide genre.  In addition, *shall* usage in writing in the legal genre appears to vary to a greater extent than *shall* usage in the non-legal genre.
```{r}
all_data %>%
  filter(!is.na(trial_number), !is.na(domain)) %>%
  group_by(trial_number, domain) %>%
  summarise(
    mean_shall = mean(num_shall, na.rm = TRUE),
    se = sd(num_shall, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  ) %>%
  ggplot(aes(x = factor(trial_number), y = mean_shall, color = domain)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_shall - se, ymax = mean_shall + se), width = 0.2) +
  labs(
    title = "'Shall' Usage by Trial (Fixed Genre per Trial)",
    x = "Trial Number",
    y = "Mean number of 'shall' tokens",
    color = "Genre"
  ) +
  theme_minimal()
```
#### Statistical Models
The outcome variable of interest in this project is *shall* usage.  However, this variable may be measured in multiple ways.  On the one hand, the number of times *shall* is used per response is a viable analytic option.  In order to assess the effect of genre and writing condition *shall* usage measured in this way, I use a random effects poisson regression model.  In the alternative, *shall* usage may be measured in binary terms, where the relevant outcome variable is whether a participant opted to use *shall* at all in their response.  This measure of *shall* usage is assessed with logistic regression.


##### General Linear Mixed Effects Model Results
 
In the model below, the effect of genre ("domain" in the code below) on the number of times *shall* was used was assessed, with individual participant ("file" in the code below) and item ("trial_index" in the code below) as random effects.  Results indicate that there is a significant effect of genre on *shall* usage (p = 0.00115).  Participants writing in the legal genre are predicted to use *shall* more frequently in the legal genre (estimated mean usage of *shall* in this condition is e^-0.8782^, or 0.415 times per response) than in the tour guide condition (estimated mean usage of *shall* in this condition is e^-5.587^, or 0.004 times the expected usage per response in the legal condition).  Although  variation across items was limited (standard deviation of random slope for item = 0.075), there was much greater variation in how much different participants adjusted in *shall* usage by genre (standard deviation of random slope for participant = 4.363).
```{r}
all_data %>%
  filter(!is.na(num_shall))%>%
glmer(num_shall~domain+(1+domain|file)+(1|trial_index), 
      data=., family = "poisson")%>%
  summary()

```

Although genre has a significant effect on *shall* usage, sequencing does not. In the model below, the effect of sequencing on the number of times *shall* was used was assessed, with individual participant and item as random effects. Here, participants writing in the editing condition were predicted to use *shall* more frequently in those writing in the from scratch condition.  Estimated mean usage of *shall* in the editing condition was e^-1.6985^, or 0.183 times per response, while estimated mean usage of *shall* in the from scratch condition is e^-1.0336^, or 0.356 times the expected usage per response in the editing condition).  However, this predicted difference is not statistically significant (p = 0.369).  The results of this model indicate variation in *shall* usage across items, with a standard deviation of random slope for items of 1.519.  Variation by partipant is limited (standard deviation of random slope for participant = 0.329).
```{r}
all_data %>%
  filter(!is.na(num_shall))%>%
glmer(num_shall~sequencing+(1+sequencing|file)+(1|trial_index), 
      data=., family = "poisson")%>%
  summary()
```

##### Logistic Regression Results

Treating *shall* usage as a binary variable, a logistic regression model predicting the presence of absence of the word in a response was used to analyze the data.  As with the linear models above, participant and item were taken as random effects.  The results of this model again indicate that genre has a significant effect on *shall* usage (p < 0.001).  Although there was little variance by item, substantial variation by participant was observed. 

```{r}
logistic_genre <- glmer(
  shall_used ~ domain + (1 + domain | file) + (1 | trial_index),
  data = all_data,
  family = binomial
)

summary(logistic_genre)
```
In the case of the logistic regression model assessing the effect of sequencing on *shall* usage, the model predicted that *shall* usage would be greater in responses produced in the editing condition, but the prediction was not statistically significant (p=0.624).  
```{r}
logistic_seq <- glmer(
  shall_used ~ sequencing + (1 + sequencing | file) + (1 | trial_index),
  data = all_data,
  family = binomial
)

summary(logistic_seq)
```

## Discussion

### Summary of Replication Attempt
I find a significant effect of genre on usage of the central modal *shall* in the responses.  This is consistent with Martínez et al.'s (2024) finding that it is genre, not writing process, which results in the distinctive linguistic properties of legalese.  I take this to indicate that support for the authors' conclusion that legalese is convoluted because legal writers want to convey something, not because the conceptual complexity of the genre demands it.  These results are consistent with the magic spell hypothesis and inconsistent with the deonticity expressing and copy-and-edit hypotheses.  In addition, I take these results to offer evidence against the deonticity expressing hypothesis because genre does appear to have a significant on *shall* usage.


### Commentary

Although the results of the study are consistent with the magic spell hypothesis, an important question remains unanswered: why do the particular strategies we see in legalese (*e.g.*, center-embedding, uncommon modals) seem to make statutes sound more authoritative?  I hypothesize that the markedness of these constructions is the explanation.  It may be the case that the infrequency of shall in other contexts allows it to be easily recognizable as serving a particular function in the legal context.  This may explain why *shall* is used in contexts where we might expect to see a more common modal like must.  Further research on this topic is needed to empirically assess this hypothesis.

## Additional Analysis
### Statistical Models for the Experiments 1 and 2 in Martínez et al. (2024)
The data from Martínez et al. (2024) experiment 1 also indicates that there is a significant effect of genre, but not sequencing, on *shall* usage.  In the case of experiment 2, the data available on OSF was too sparse to properly assess with the analysis plan specified in this project. 

#### General Linear Mixed Effects Model Results
```{r}
# shall usage by genre in experiment 1
exp1_data %>%
  filter(!is.na(num_shall_exp1))%>%
glmer(num_shall_exp1~domain+(1+domain|column_name), 
      data=., family = "poisson")%>%
  summary()
```

```{r}
# shall usage by sequencing in experiment 1
exp1_data %>%
  filter(!is.na(num_shall_exp1))%>%
glmer(num_shall_exp1~sequencing+(1+sequencing|column_name), 
      data=., family = "poisson")%>%
  summary()
```

```{r}
# shall usage by genre in experiment 2
exp2_data %>%
  filter(!is.na(num_shall_exp2))%>%
glmer(num_shall_exp2~genre+(1+genre|item), 
      data=., family = "poisson")%>%
  summary()
```

#### Logistic Regression Results

```{r}
# shall usage by genre in experiment 1
logistic_genre1 <- glmer(
  shall_used ~ domain + (1 + domain | PROLIFIC_PID) + (1 | column_name),
  data = exp1_data,
  family = binomial
)

summary(logistic_genre1)
```
```{r}
# shall usage by sequencing in experiment 1
logistic_seq1 <- glmer(
  shall_used ~ sequencing + (1 + sequencing | PROLIFIC_PID) + (1 | column_name),
  data = exp1_data,
  family = binomial
)

summary(logistic_seq1)
```
```{r}
# shall usage by genre in experiment 2
logistic_genre2 <- glmer(
  shall_used ~ genre + (1 + genre | PROLIFIC_PID) + (1 | item),
  data = exp2_data,
  family = binomial
)

summary(logistic_genre2)
```